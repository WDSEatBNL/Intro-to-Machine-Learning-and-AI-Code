{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFX80cw8k5QrLERfHw0yM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WDSEatBNL/Intro-to-Machine-Learning-and-AI-Code/blob/master/Machine_Learning_SciKit_larger_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a843501"
      },
      "source": [
        "Import all necessary Python libraries required for the project.\n",
        "\n",
        "These include `skimage` for image processing, `matplotlib.pyplot` for plotting, `numpy` for numerical operations, `joblib` for saving/loading Python objects, `os` for interacting with the operating system, `collections.Counter` for counting items, `sklearn` modules for machine learning (SGDClassifier, StandardScaler, train_test_split), and `seaborn` for enhanced visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh9DznxdoYHB"
      },
      "outputs": [],
      "source": [
        "import skimage as skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from collections import Counter\n",
        "from skimage import io\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from skimage.feature import hog\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ebca6d2"
      },
      "source": [
        "Use the `!git clone` command to download a GitHub repository named 'Intro-to-Machine-Learning-and-AI-Files'. This repository is expected to contain the image datasets used for training and testing the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WDSEatBNL/Intro-to-Machine-Learning-and-AI-Files"
      ],
      "metadata": {
        "id": "x1HCypZlpGtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "501f8981"
      },
      "source": [
        "Define a function `load_and_preprocess_images` that reads image files, extracts their labels (based on subfolder names), and stores the image data, filenames, and labels into a dictionary. It then saves this dictionary to a `.pkl` file using `joblib`.\n",
        "\n",
        "The function is used twice: once for the 'bigdata' (training) set and once for the 'test' set.\n",
        "\n",
        "Finally, it prints the number of images and label counts for both datasets and prepares the `X_train`, `y_train`, `X_test`, and `y_test` numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images(base_dir, pkl_filename):\n",
        "    data = dict()\n",
        "    data['label'] = []\n",
        "    data['filename'] = []\n",
        "    data['data'] = []\n",
        "\n",
        "    for subdir in os.listdir(base_dir):\n",
        "        current_path = os.path.join(base_dir, subdir)\n",
        "        if not os.path.isdir(current_path):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(current_path):\n",
        "            filepath = os.path.join(current_path, filename)\n",
        "            image = io.imread(filepath)\n",
        "            data['label'].append(subdir)\n",
        "            data['filename'].append(filename)\n",
        "            data['data'].append(image)\n",
        "\n",
        "    joblib.dump(data, pkl_filename)\n",
        "    return data\n",
        "\n",
        "pklname = \"bigdata.pkl\"\n",
        "pklname_test = \"testdata.pkl\"\n",
        "\n",
        "data_path = r'./Intro-to-Machine-Learning-and-AI-Files/bigdata'\n",
        "data = load_and_preprocess_images(data_path, pklname)\n",
        "\n",
        "test_path = r'./Intro-to-Machine-Learning-and-AI-Files/test'\n",
        "test_data = load_and_preprocess_images(test_path, pklname_test)\n",
        "\n",
        "base_name = 'bigdata'\n",
        "width = 288\n",
        "\n",
        "print('number of training images: ', len(data['data']))\n",
        "print(Counter(data['label']))\n",
        "print('number of test images: ', len(test_data['data']))\n",
        "\n",
        "labels = np.unique(data['label'])\n",
        "\n",
        "X_train = np.array(data['data'])\n",
        "y_train = np.array(data['label'])\n",
        "X_test = np.array(test_data['data'])\n",
        "y_test = np.array(test_data['label'])"
      ],
      "metadata": {
        "id": "u4ABH7hepH5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b75aac61"
      },
      "source": [
        "Define two custom `Transformer` classes: `RGB2GrayTransformer` converts RGB images to grayscale, and `HogTransformer` extracts Histogram of Oriented Gradients (HOG) features from images.\n",
        "\n",
        "These transformers are then represented along with a `StandardScaler`. The training and test image data (`X_train`, `X_test`) are preprocessed sequentially: first converted to grayscale, then HOG features are extracted, and finally, the features are scaled.\n",
        "\n",
        "An `SGDClassifier` model is then initialized and trained on the preprocessed training data (`X_train_prepared`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
        "\n",
        "class HogTransformer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, y=None, orientations=9,\n",
        "                 pixels_per_cell=(8, 8),\n",
        "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
        "        self.y = y\n",
        "        self.orientations = orientations\n",
        "        self.pixels_per_cell = pixels_per_cell\n",
        "        self.cells_per_block = cells_per_block\n",
        "        self.block_norm = block_norm\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "\n",
        "        def local_hog(X):\n",
        "            return hog(X,\n",
        "                       orientations=self.orientations,\n",
        "                       pixels_per_cell=self.pixels_per_cell,\n",
        "                       cells_per_block=self.cells_per_block,\n",
        "                       block_norm=self.block_norm)\n",
        "\n",
        "        try:\n",
        "            return np.array([local_hog(img) for img in X])\n",
        "        except:\n",
        "            return np.array([local_hog(img) for img in X])\n",
        "\n",
        "grayify = RGB2GrayTransformer()\n",
        "hogify = HogTransformer(pixels_per_cell=(14, 14), cells_per_block=(2,2), orientations=9, block_norm='L2-Hys')\n",
        "scalify = StandardScaler()\n",
        "\n",
        "X_train_gray = grayify.fit_transform(X_train)\n",
        "X_train_hog = hogify.fit_transform(X_train_gray)\n",
        "X_train_prepared = scalify.fit_transform(X_train_hog)\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)\n",
        "sgd_clf.fit(X_train_prepared, y_train)\n",
        "\n",
        "X_test_gray = grayify.transform(X_test)\n",
        "X_test_hog = hogify.transform(X_test_gray)\n",
        "X_test_prepared = scalify.transform(X_test_hog)"
      ],
      "metadata": {
        "id": "JhOiqCNxpdEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b04ce86e"
      },
      "source": [
        "Use the trained `SGDClassifier` (`sgd_clf`) to make predictions on the preprocessed test data (`X_test_prepared`).\n",
        "\n",
        "Then print the true labels (`y_test`), a boolean array indicating whether each prediction matches the true label, and the array of predicted labels (`y_pred`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = sgd_clf.predict(X_test_prepared)\n",
        "print(y_test)\n",
        "print(np.array(y_pred == y_test))\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "XdkJZ2IQpkE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show each validation image with its predicted category"
      ],
      "metadata": {
        "id": "cuMS4movo3kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "    if i >= 30:\n",
        "        break\n",
        "    ax = plt.subplot(6, 5, i + 1)\n",
        "    plt.imshow(X_test[i])\n",
        "    plt.title(y_pred[i])\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gWnboPblqg3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the accuracy of the model in the form of percent correctly identified"
      ],
      "metadata": {
        "id": "oROQQZzZo6RJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage correct: ', 100*np.sum(y_pred == y_test)/len(y_test))"
      ],
      "metadata": {
        "id": "4QQwgs23prEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59f04d9b"
      },
      "source": [
        "Generate and display a confusion matrix to evaluate the performance of the classification model in more detail.\n",
        "\n",
        "Use `sklearn.metrics.confusion_matrix` to compute the matrix, normalizes it to show proportions, and then visualizes it as a heatmap using `seaborn.heatmap`.\n",
        "\n",
        "The heatmap shows the proportion of true labels versus predicted labels for each class ('bird', 'cat', 'dog'), helping to identify which classes are being confused by the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred, normalize='all')\n",
        "cm_rounded = np.around(cm, decimals=2)\n",
        "fig, ax_cm = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(cm_rounded, annot=True, annot_kws={\"size\": 20}, cbar=False, cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "ax_cm.set_ylabel('True Values', fontsize=20)\n",
        "ax_cm.set_xlabel('Predicted Values', fontsize=20)\n",
        "ax_cm.set_title('Confusion Matrix', fontsize=20)\n",
        "ax_cm.tick_params(axis='x', labelsize=20)\n",
        "ax_cm.tick_params(axis='y', labelsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6k3VR0Hpq64K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-g90ibbltNpi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}