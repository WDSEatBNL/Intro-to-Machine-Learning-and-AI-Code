{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPZYu+U+SqeTKzZmG4ad51N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WDSEatBNL/Intro-to-Machine-Learning-and-AI-Code/blob/master/Machine_Learning_SciKit_Type_in_Categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all necessary Python libraries required for the project.\n",
        "\n",
        "These include `skimage` for image processing, `matplotlib.pyplot` for plotting, numpy for numerical operations, `joblib` for saving/loading Python objects, `os` for interacting with the operating system, `collections.Counter` for counting items, and `sklearn` modules for machine learning (`SGDClassifier`, `StandardScaler`, `train_test_split`)."
      ],
      "metadata": {
        "id": "UFdwy4z5UNg3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Qr05XAR131"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skimage import io\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `!git clone` command to download a GitHub repository named 'Intro-to-Machine-Learning-and-AI-Files'. This repository is expected to contain the image datasets used for training and testing the machine learning model."
      ],
      "metadata": {
        "id": "fRg4W96SzSrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WDSEatBNL/Intro-to-Machine-Learning-and-AI-Files"
      ],
      "metadata": {
        "id": "XSpVjIgUzXNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the files from the \"images\" folder (found in \"content/Intro-to-Machine-Learning-and-AI-Files) and ask the user to name the images based on the categories from their card game\n",
        "\n",
        "***Instructions:*** After running the cell below, you will see an image, an input box, and a submit button. Enter your label in the input box and click 'Submit Label' to proceed to the next image."
      ],
      "metadata": {
        "id": "V-Jqc4XPUEK2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f24b2c51"
      },
      "source": [
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 288\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_dir = r'/content/Intro-to-Machine-Learning-and-AI-Files/images'\n",
        "image_files = [f for f in os.listdir(train_data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "collected_image_labels = {}\n",
        "current_image_index = 0\n",
        "\n",
        "image_widget = widgets.Image(width=300)\n",
        "label_input = widgets.Text(description='Label:')\n",
        "submit_button = widgets.Button(description='Submit Label')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def display_next_image():\n",
        "    global current_image_index\n",
        "    if current_image_index < len(image_files):\n",
        "        current_image_file = image_files[current_image_index]\n",
        "        filepath = os.path.join(train_data_dir, current_image_file)\n",
        "\n",
        "        with open(filepath, 'rb') as f:\n",
        "            image_data = f.read()\n",
        "        image_widget.value = image_data\n",
        "        label_input.value = '' # Clear previous input\n",
        "        label_input.placeholder = f\"Enter label for {current_image_file}\"\n",
        "        with output_area:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"Labeling image {current_image_index + 1}/{len(image_files)}: {current_image_file}\")\n",
        "    else:\n",
        "        with output_area:\n",
        "            clear_output(wait=True)\n",
        "            print(\"Labeling complete!\")\n",
        "            print(\"Collected labels:\")\n",
        "            for filename, label in collected_image_labels.items():\n",
        "                print(f\"  {filename}: {label}\")\n",
        "        submit_button.disabled = True\n",
        "        label_input.disabled = True\n",
        "\n",
        "def on_submit_button_clicked(b):\n",
        "    global current_image_index\n",
        "    current_image_file = image_files[current_image_index]\n",
        "    label = label_input.value.strip()\n",
        "    if label:\n",
        "        collected_image_labels[current_image_file] = label\n",
        "        current_image_index += 1\n",
        "        display_next_image()\n",
        "    else:\n",
        "        with output_area:\n",
        "            print(\"Please enter a label before submitting.\")\n",
        "\n",
        "submit_button.on_click(on_submit_button_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    image_widget,\n",
        "    widgets.HBox([label_input, submit_button]),\n",
        "    output_area\n",
        "]))\n",
        "display_next_image()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the text labels you provided for your images, identifies all the unique categories, and then creates a numerical mapping.\n",
        "\n",
        "Then sort your image filenames and use this mapping to convert each image's text label into a corresponding integer. This process is essential because machine learning models require numerical inputs for training."
      ],
      "metadata": {
        "id": "hWIFNVYJ5t51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_string_labels = list(collected_image_labels.values())\n",
        "class_names = sorted(list(set(all_string_labels)))\n",
        "\n",
        "label_to_index = {label: i for i, label in enumerate(class_names)}\n",
        "\n",
        "sorted_image_filenames = sorted(image_files)\n",
        "ordered_integer_labels = [label_to_index[collected_image_labels[filename]] for filename in sorted_image_filenames]\n",
        "\n",
        "print(f\"Unique class names (sorted): {class_names}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")"
      ],
      "metadata": {
        "id": "Hq1rx0tZ5waA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is responsible for preparing your image data for the scikit-learn model. It loads and resizes each image, flattens it into a one-dimensional array, then combines all flattened images into a single dataset.\n",
        "\n",
        "It then splits the data into a training set and a validation set (i.e., set aside 20% of the images for testing)."
      ],
      "metadata": {
        "id": "9xh6R3C7UgS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = []\n",
        "for filename in sorted_image_filenames:\n",
        "    filepath = os.path.join(train_data_dir, filename)\n",
        "    # Load image and resize\n",
        "    image = io.imread(filepath)\n",
        "    image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH)).numpy() # Use tf.image.resize for consistent resizing\n",
        "\n",
        "    # Flatten the image for scikit-learn\n",
        "    image_data.append(image.flatten())\n",
        "\n",
        "X = np.array(image_data)\n",
        "y = np.array(ordered_integer_labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y # stratify helps maintain class proportions\n",
        ")\n",
        "\n",
        "# Scale features (important for MLPClassifier)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data preparation for scikit-learn complete:\")\n",
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "Jh80IbICUkff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the model for training: specify a hidden layer with 100 neurons, set the maximum number of iterations (max_iter), and set a random_state for reproducibility."
      ],
      "metadata": {
        "id": "PoytBA-w9jd0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3IzFU19u"
      },
      "source": [
        "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42, verbose=True)\n",
        "\n",
        "print(\"Scikit-learn MLPClassifier model created.\")\n",
        "print(\"Model parameters:\")\n",
        "print(model.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and assign a category name to each image in the validation set. This is done many times, showing each iteration and the loss value. These iterations are called epochs. The model will rerun until the loss improvement is less than 0.0001 between epochs.\n",
        "\n",
        "*   **Higher Loss:** Means the model's predictions are far from the actual values, indicating poor performance.\n",
        "*   **Lower Loss:** Means the model's predictions are closer to the actual values, indicating better performance."
      ],
      "metadata": {
        "id": "GGOFklgm_x6C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d481d4d8"
      },
      "source": [
        "print(\"Training the MLPClassifier model...\")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Making predictions on the test set...\")\n",
        "predicted_classes = model.predict(X_test_scaled)\n",
        "\n",
        "# Map integer predictions back to class names for readability\n",
        "predicted_class_names = [class_names[i] for i in predicted_classes]\n",
        "actual_class_names = [class_names[i] for i in y_test]\n",
        "\n",
        "print(\"Training and prediction complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show each validation image with its predicted category"
      ],
      "metadata": {
        "id": "t0Fzd2X8VQnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 12))\n",
        "num_test_images = len(predicted_class_names)\n",
        "\n",
        "for i in range(num_test_images):\n",
        "    ax = plt.subplot(4, int(np.ceil(num_test_images/4)), i + 1)\n",
        "\n",
        "    # Get the original (unscaled, unflattened) image from X_test\n",
        "    # X_test contains the flattened images, so we need to reshape them\n",
        "    image_to_display = X_test[i].reshape(IMG_HEIGHT, IMG_WIDTH, 3).astype('uint8')\n",
        "\n",
        "    plt.imshow(image_to_display)\n",
        "    plt.title(f\"{predicted_class_names[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mZgtFcVyVUks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the accuracy of the model in the form of percent correctly identified"
      ],
      "metadata": {
        "id": "NOzMD6n9VXBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage correct: ', 100*np.sum(y_test == predicted_classes)/len(predicted_classes))"
      ],
      "metadata": {
        "id": "4GhGg3iYVZdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}